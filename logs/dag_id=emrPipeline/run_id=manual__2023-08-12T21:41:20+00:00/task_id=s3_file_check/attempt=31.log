[2023-08-13T08:31:21.918+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: emrPipeline.s3_file_check manual__2023-08-12T21:41:20+00:00 [queued]>
[2023-08-13T08:31:21.947+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: emrPipeline.s3_file_check manual__2023-08-12T21:41:20+00:00 [queued]>
[2023-08-13T08:31:21.947+0000] {taskinstance.py:1308} INFO - Starting attempt 31 of 31
[2023-08-13T08:31:22.002+0000] {taskinstance.py:1327} INFO - Executing <Task(S3KeySensor): s3_file_check> on 2023-08-12 21:41:20+00:00
[2023-08-13T08:31:22.009+0000] {standard_task_runner.py:57} INFO - Started process 10474 to run task
[2023-08-13T08:31:22.048+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'emrPipeline', 's3_file_check', 'manual__2023-08-12T21:41:20+00:00', '--job-id', '615', '--raw', '--subdir', 'DAGS_FOLDER/emr.py', '--cfg-path', '/tmp/tmpqjk9843z']
[2023-08-13T08:31:22.056+0000] {standard_task_runner.py:85} INFO - Job 615: Subtask s3_file_check
[2023-08-13T08:31:22.089+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.9/site-packages/***/settings.py:195: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  SQL_ALCHEMY_CONN = conf.get("database", "SQL_ALCHEMY_CONN")

[2023-08-13T08:31:22.171+0000] {task_command.py:410} INFO - Running <TaskInstance: emrPipeline.s3_file_check manual__2023-08-12T21:41:20+00:00 [running]> on host 484e6be077e8
[2023-08-13T08:31:22.224+0000] {abstractoperator.py:594} ERROR - Exception rendering Jinja template for task 's3_file_check', field 'bucket_key'. Template: "{{ dag_run.conf['s3_location'] }}"
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/abstractoperator.py", line 586, in _do_render_template_fields
    rendered_content = self.render_template(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/template/templater.py", line 156, in render_template
    return self._render(template, context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/abstractoperator.py", line 540, in _render
    return super()._render(template, context, dag=dag)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/template/templater.py", line 113, in _render
    return render_template_to_string(template, context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/helpers.py", line 288, in render_template_to_string
    return render_template(template, cast(MutableMapping[str, Any], context), native=False)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/helpers.py", line 283, in render_template
    return "".join(nodes)
  File "<template>", line 12, in root
  File "/home/airflow/.local/lib/python3.9/site-packages/jinja2/runtime.py", line 852, in _fail_with_undefined_error
    raise self._undefined_exception(self._undefined_message)
jinja2.exceptions.UndefinedError: 'dict object' has no attribute 's3_location'
[2023-08-13T08:31:22.226+0000] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1407, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1531, in _execute_task_with_callbacks
    task_orig = self.render_templates(context=context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 2179, in render_templates
    original_task.render_template_fields(context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 1254, in render_template_fields
    self._do_render_template_fields(self, self.template_fields, context, jinja_env, set())
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/abstractoperator.py", line 586, in _do_render_template_fields
    rendered_content = self.render_template(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/template/templater.py", line 156, in render_template
    return self._render(template, context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/abstractoperator.py", line 540, in _render
    return super()._render(template, context, dag=dag)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/template/templater.py", line 113, in _render
    return render_template_to_string(template, context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/helpers.py", line 288, in render_template_to_string
    return render_template(template, cast(MutableMapping[str, Any], context), native=False)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/helpers.py", line 283, in render_template
    return "".join(nodes)
  File "<template>", line 12, in root
  File "/home/airflow/.local/lib/python3.9/site-packages/jinja2/runtime.py", line 852, in _fail_with_undefined_error
    raise self._undefined_exception(self._undefined_message)
jinja2.exceptions.UndefinedError: 'dict object' has no attribute 's3_location'
[2023-08-13T08:31:22.234+0000] {taskinstance.py:1345} INFO - Marking task as FAILED. dag_id=emrPipeline, task_id=s3_file_check, execution_date=20230812T214120, start_date=20230813T083121, end_date=20230813T083122
[2023-08-13T08:31:22.247+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 615 for task s3_file_check ('dict object' has no attribute 's3_location'; 10474)
[2023-08-13T08:31:22.284+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2023-08-13T08:31:22.315+0000] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
